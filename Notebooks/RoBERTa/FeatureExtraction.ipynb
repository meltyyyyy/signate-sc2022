{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/anaconda3/envs/sc/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/abe/anaconda3/envs/sc/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "plt.style.use('seaborn-pastel')\n",
    "sns.set_palette(\"winter_r\")\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    script = \"roberta/feature_extraction\"\n",
    "\n",
    "    n_splits = 5\n",
    "    seed = 42\n",
    "\n",
    "    batch_size = 16\n",
    "    n_classes = 4\n",
    "    n_epochs = 10\n",
    "\n",
    "    # bert\n",
    "    model_name = \"roberta-base\"\n",
    "    weight_decay = 2e-5\n",
    "    beta = (0.9, 0.98)\n",
    "    max_len = 128\n",
    "    lr = 2e-5\n",
    "    num_warmup_steps_rate = 0.01\n",
    "    clip_grad_norm = None\n",
    "    gradient_accumulation_steps = 1\n",
    "    num_eval = 1\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Reka Env\n",
    "    dir_path = \"/home/abe/kaggle/signate-sc2022\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def path_setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    cfg.INPUT = os.path.join(Config.dir_path, 'input')\n",
    "    cfg.OUTPUT = os.path.join(Config.dir_path, 'output')\n",
    "    cfg.SUBMISSION = os.path.join(Config.dir_path, 'submissions')\n",
    "    cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, Config.script)\n",
    "    cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, \"model\")\n",
    "    cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, \"preds\")\n",
    "    cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, \"fig\")\n",
    "    cfg.NOTEBOOK = os.path.join(Config.dir_path, \"Notebooks\")\n",
    "    cfg.SCRIPT = os.path.join(Config.dir_path, \"scripts\")\n",
    "\n",
    "    # make dir\n",
    "    for dir in [\n",
    "            cfg.INPUT,\n",
    "            cfg.OUTPUT,\n",
    "            cfg.SUBMISSION,\n",
    "            cfg.OUTPUT_EXP,\n",
    "            cfg.EXP_MODEL,\n",
    "            cfg.EXP_PREDS,\n",
    "            cfg.EXP_FIG,\n",
    "            cfg.NOTEBOOK,\n",
    "            cfg.SCRIPT]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, model_name=\"roberta-base\", criterion=None):\n",
    "        super().__init__()\n",
    "        self.criterion = criterion\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=self.config\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        outputs = self.backbone(**inputs)[\"last_hidden_state\"]\n",
    "        outputs = outputs[:, 0, :]\n",
    "        if labels is not None:\n",
    "            logits = self.fc(outputs)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.fc(outputs)\n",
    "            return logits\n",
    "\n",
    "\n",
    "class BertSequenceVectorizer:\n",
    "    def __init__(self, model, tokenizer, max_len):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert_model = model\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def vectorize(self, sentence: str) -> np.array:\n",
    "        inp = self.tokenizer.encode(sentence)\n",
    "        len_inp = len(inp)\n",
    "\n",
    "        if len_inp >= self.max_len:\n",
    "            inputs = inp[:self.max_len]\n",
    "            masks = [1] * self.max_len\n",
    "        else:\n",
    "            inputs = inp + [0] * (self.max_len - len_inp)\n",
    "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
    "\n",
    "        inputs_tensor = torch.tensor(\n",
    "            [inputs], dtype=torch.long).to(\n",
    "            self.device)\n",
    "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
    "\n",
    "        bert_out = self.bert_model(inputs_tensor, masks_tensor)\n",
    "        seq_out, pooled_out = bert_out['last_hidden_state'], bert_out['pooler_output']\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return seq_out.cpu().detach().numpy()\n",
    "        else:\n",
    "            return seq_out[0][0].detach().numpy()\n",
    "\n",
    "\n",
    "def vectorize(df: pd.DataFrame, tokenizer, model_paths):\n",
    "    assert \"description\" in df.columns\n",
    "    df['feature'] = 0\n",
    "    print('\\n'.join(model_paths))\n",
    "    for _, model_weight in enumerate(model_paths):\n",
    "        model = BERTModel()\n",
    "        model.load_state_dict(torch.load(model_weight))\n",
    "        model = model.to(cfg.device)\n",
    "\n",
    "        BSV = BertSequenceVectorizer(model, tokenizer, cfg.max_len)\n",
    "        df['feature'] += df['description'].progress_apply(lambda x: BSV.vectorize(x))\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    df['feature'] = df['feature'] / len(model_paths)\n",
    "    return pd.DataFrame(np.stack(df['feature']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(Config.seed)\n",
    "cfg = path_setup(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [p for p in sorted(glob(os.path.join(cfg.dir_path, \"/output/roberta/baseline\", 'fold*.pth')))]\n",
    "train = pd.read_csv(os.path.join(cfg.INPUT, \"train_cleaned.csv\"))\n",
    "print(train['description'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train = vectorize(train, tokenizer, model_paths)\n",
    "print(feat_train.head())\n",
    "print(feat_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8c426eaf553261faa5dcddf5888c67da4c659d06ea0be71410dda2f5a31e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
