{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/anaconda3/envs/sc/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/abe/anaconda3/envs/sc/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "plt.style.use('seaborn-pastel')\n",
    "sns.set_palette(\"winter_r\")\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    script = \"roberta/feature_extraction\"\n",
    "\n",
    "    n_splits = 5\n",
    "    seed = 42\n",
    "\n",
    "    batch_size = 16\n",
    "    n_classes = 4\n",
    "    n_epochs = 10\n",
    "\n",
    "    # bert\n",
    "    model_name = \"roberta-base\"\n",
    "    weight_decay = 2e-5\n",
    "    beta = (0.9, 0.98)\n",
    "    max_len = 128\n",
    "    lr = 2e-5\n",
    "    num_warmup_steps_rate = 0.01\n",
    "    clip_grad_norm = None\n",
    "    gradient_accumulation_steps = 1\n",
    "    num_eval = 1\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Reka Env\n",
    "    dir_path = \"/home/abe/kaggle/signate-sc2022\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def path_setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    cfg.INPUT = os.path.join(Config.dir_path, 'input')\n",
    "    cfg.OUTPUT = os.path.join(Config.dir_path, 'output')\n",
    "    cfg.SUBMISSION = os.path.join(Config.dir_path, 'submissions')\n",
    "    cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, Config.script)\n",
    "    cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, \"model\")\n",
    "    cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, \"preds\")\n",
    "    cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, \"fig\")\n",
    "    cfg.NOTEBOOK = os.path.join(Config.dir_path, \"Notebooks\")\n",
    "    cfg.SCRIPT = os.path.join(Config.dir_path, \"scripts\")\n",
    "\n",
    "    # make dir\n",
    "    for dir in [\n",
    "            cfg.INPUT,\n",
    "            cfg.OUTPUT,\n",
    "            cfg.SUBMISSION,\n",
    "            cfg.OUTPUT_EXP,\n",
    "            cfg.EXP_MODEL,\n",
    "            cfg.EXP_PREDS,\n",
    "            cfg.EXP_FIG,\n",
    "            cfg.NOTEBOOK,\n",
    "            cfg.SCRIPT]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(Config.seed)\n",
    "cfg = path_setup(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, model_name=\"roberta-base\", criterion=None):\n",
    "        super().__init__()\n",
    "        self.criterion = criterion\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=self.config\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        \n",
    "        if labels is None:\n",
    "            \n",
    "            logits = self.fc(outputs[\"last_hidden_state\"][:, 0, :])\n",
    "            return logits, outputs\n",
    "        \n",
    "        outputs = outputs[\"last_hidden_state\"][:, 0, :]\n",
    "        logits = self.fc(outputs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "class BertSequenceVectorizer:\n",
    "    def __init__(self, model, tokenizer, max_len):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert_model = model\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def vectorize(self, sentence: str) -> np.array:\n",
    "        inp = self.tokenizer.encode(sentence)\n",
    "        len_inp = len(inp)\n",
    "\n",
    "        if len_inp >= self.max_len:\n",
    "            inputs = inp[:self.max_len]\n",
    "            masks = [1] * self.max_len\n",
    "        else:\n",
    "            inputs = inp + [0] * (self.max_len - len_inp)\n",
    "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
    "\n",
    "        inputs_tensor = torch.tensor(\n",
    "            [inputs], dtype=torch.long).to(\n",
    "            self.device)\n",
    "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
    "        _, bert_out = self.bert_model({\"input_ids\" : inputs_tensor, \"attention_mask\": masks_tensor})\n",
    "        seq_out, pooled_out = bert_out['last_hidden_state'], bert_out['pooler_output']\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return seq_out[0][0].cpu().detach().numpy()\n",
    "        else:\n",
    "            return seq_out[0][0].detach().numpy()\n",
    "\n",
    "\n",
    "def vectorize(df: pd.DataFrame, tokenizer, model_paths):\n",
    "    assert \"description\" in df.columns\n",
    "    df['feature'] = 0\n",
    "    print('\\n'.join(model_paths))\n",
    "    for _, model_weight in enumerate(model_paths):\n",
    "        model = BERTModel()\n",
    "        model.load_state_dict(torch.load(model_weight))\n",
    "        model = model.to(cfg.device)\n",
    "\n",
    "        BSV = BertSequenceVectorizer(model, tokenizer, cfg.max_len)\n",
    "        df['feature'] += df['description'].progress_apply(lambda x: BSV.vectorize(x))\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    df['feature'] = df['feature'] / len(model_paths)\n",
    "    return pd.DataFrame(np.stack(df['feature']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    develop cutting edge web applications perform ...\n",
      "1    designs develops high quality scalable efficie...\n",
      "2    functions point person network strategy work r...\n",
      "3    work technical design development release depl...\n",
      "4    quantify resources required task project relat...\n",
      "5    participates standard business technical infor...\n",
      "6    create project plans establish timelines estab...\n",
      "7    facilitate pre sales initiatives live demonstr...\n",
      "8    consolidate dashboards across team help drive ...\n",
      "9    maintain improve existing predictive models ev...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "model_paths = [p for p in sorted(glob(os.path.join(cfg.dir_path + \"/output/roberta/baseline/model/\", \"fold*.pth\")))]\n",
    "train = pd.read_csv(os.path.join(cfg.INPUT, \"train_cleaned.csv\"))\n",
    "print(train['description'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abe/kaggle/signate-sc2022/output/roberta/baseline/model/fold0.pth\n",
      "/home/abe/kaggle/signate-sc2022/output/roberta/baseline/model/fold1.pth\n",
      "/home/abe/kaggle/signate-sc2022/output/roberta/baseline/model/fold2.pth\n",
      "/home/abe/kaggle/signate-sc2022/output/roberta/baseline/model/fold3.pth\n",
      "/home/abe/kaggle/signate-sc2022/output/roberta/baseline/model/fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1516/1516 [00:13<00:00, 110.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.054320  0.163751 -0.316622  0.054401  0.186521 -0.138654 -0.080279   \n",
      "1  0.007138  0.245675 -0.074354  0.119374 -0.006550 -0.112559 -0.089299   \n",
      "2  0.175423  0.014750  0.098829 -0.109835 -0.144359  0.000833 -0.143365   \n",
      "3 -0.181164  0.174353 -0.332650  0.115873  0.305775 -0.111456 -0.005911   \n",
      "4  0.248364  0.051887  0.016210 -0.128455 -0.241048 -0.063836 -0.077739   \n",
      "\n",
      "        7         8         9    ...       758       759       760       761  \\\n",
      "0 -0.165954 -0.291944 -0.159278  ... -0.076210 -0.080901 -0.324941 -0.050864   \n",
      "1 -0.085308 -0.049521 -0.034661  ... -0.044947 -0.102488 -0.210471  0.045380   \n",
      "2 -0.042509  0.093194  0.068069  ... -0.027346 -0.108323 -0.004558 -0.043174   \n",
      "3 -0.079442 -0.189538 -0.163131  ... -0.114342 -0.014626 -0.263512 -0.006301   \n",
      "4 -0.099214  0.078999  0.171830  ... -0.095246 -0.020634 -0.006083  0.022993   \n",
      "\n",
      "        762       763       764       765       766       767  \n",
      "0 -0.109938  0.066453  0.169820 -0.018920  0.146084  0.007457  \n",
      "1 -0.009830 -0.030532 -0.012143 -0.172718  0.081613  0.152289  \n",
      "2  0.114141 -0.081161 -0.268030 -0.097786 -0.142855 -0.027997  \n",
      "3 -0.096579  0.083416  0.212404 -0.006479  0.146776 -0.030369  \n",
      "4  0.085002 -0.082008 -0.270176 -0.177552 -0.084615 -0.030651  \n",
      "\n",
      "[5 rows x 768 columns]\n",
      "(1516, 768)\n"
     ]
    }
   ],
   "source": [
    "feat_train = vectorize(train, tokenizer, model_paths)\n",
    "print(feat_train.head())\n",
    "print(feat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8c426eaf553261faa5dcddf5888c67da4c659d06ea0be71410dda2f5a31e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
